# -*- coding: utf-8 -*-
"""Dynamic Price Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rvu_c8oVTuwjXYdkkTzQ0bHhMAj28DYM
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split
import os

ONLINE_RETAIL_PATH = "Online_Retail.csv"
RETAIL_DEMAND_PATH = "Retail_Demand.csv"
SNAPSHOT_DATE = None

retail_df = pd.read_csv("/content/online_retail_II.csv")

demand_df = pd.read_csv("/content/retail_store_inventory.csv")

retail_df.head()

demand_df.head()

def safe_to_numeric(df, cols):
    for c in cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors='coerce')
    return df

if 'InvoiceDate' in retail_df.columns:
    retail_df['InvoiceDate'] = pd.to_datetime(retail_df['InvoiceDate'], errors='coerce', dayfirst=True)
if 'Date' in demand_df.columns:
    demand_df['Date'] = pd.to_datetime(demand_df['Date'], errors='coerce')

retail_df = safe_to_numeric(retail_df, ['Quantity', 'Price'])
demand_df = safe_to_numeric(demand_df, ['Inventory Level', 'Units Sold', 'Units Ordered', 'Demand Forecast', 'Price'])

retail_df.drop_duplicates(inplace=True)
demand_df.drop_duplicates(inplace=True)

retail_df.columns = [c.strip() for c in retail_df.columns]
if 'Customer ID' in retail_df.columns:
    retail_df.rename(columns={'Customer ID': 'CustomerID'}, inplace=True)
retail_df['CustomerID'] = retail_df['CustomerID'].fillna('ANON')

retail_df = retail_df[
    retail_df['Quantity'].notna() & (retail_df['Quantity'] > 0) &
    retail_df['Price'].notna() & (retail_df['Price'] > 0)
]

if 'Units Sold' in demand_df.columns and 'Price' in demand_df.columns:
    demand_df = demand_df[demand_df['Units Sold'].notna() & demand_df['Price'].notna()]
    demand_df = demand_df[(demand_df['Units Sold'] >= 0) & (demand_df['Price'] > 0)]

retail_df.columns = [c.strip() for c in retail_df.columns]
demand_df.columns = [c.strip() for c in demand_df.columns]

if 'StockCode' in retail_df.columns and 'Product ID' in demand_df.columns:
    retail_df.rename(columns={'StockCode': 'Product ID'}, inplace=True)
elif 'StockCode' in retail_df.columns:
    retail_df.rename(columns={'StockCode': 'Product_ID'}, inplace=True)

if 'Product ID' in retail_df.columns:
    product_col = 'Product ID'
elif 'Product_ID' in retail_df.columns:
    product_col = 'Product_ID'
elif 'StockCode' in retail_df.columns:
    product_col = 'StockCode'
else:
    product_col = None

retail_df['TotalValue'] = retail_df['Quantity'] * retail_df['Price']

"""Recency: Days since last purchase (SNAPSHOT_DATE - last_invoice_date)

Frequency: Number of transactions per customer

Monetary: Total money spent per customer
"""

if SNAPSHOT_DATE is None:
    max_dates = []
    if 'InvoiceDate' in retail_df.columns:
        max_dates.append(retail_df['InvoiceDate'].max())
    if 'Date' in demand_df.columns:
        max_dates.append(demand_df['Date'].max())
    valid_dates = [d for d in max_dates if pd.notnull(d)]
    SNAPSHOT_DATE = (max(valid_dates) + pd.Timedelta(days=1)) if valid_dates else pd.Timestamp.today()

if 'CustomerID' in retail_df.columns and not retail_df.empty:
    cust_grp = retail_df.groupby('CustomerID').agg({
        'InvoiceDate': lambda x: (SNAPSHOT_DATE - x.max()).days if x.notna().any() else np.nan,
        'Invoice': 'nunique' if 'Invoice' in retail_df.columns else 'count',
        'TotalValue': 'sum'
    }).reset_index().rename(columns={
        'InvoiceDate': 'Recency',
        'Invoice': 'Frequency',
        'TotalValue': 'Monetary'
    })
else:
    cust_grp = pd.DataFrame(columns=['CustomerID', 'Recency', 'Frequency', 'Monetary'])

cust_grp['Recency'] = cust_grp['Recency'].fillna(cust_grp['Recency'].median() if not cust_grp['Recency'].empty else 0)
cust_grp['Frequency'] = cust_grp['Frequency'].fillna(0)
cust_grp['Monetary'] = cust_grp['Monetary'].fillna(0.0)

if not cust_grp.empty:
    scaler = StandardScaler()
    cust_grp[['Recency_s', 'Frequency_s', 'Monetary_s']] = scaler.fit_transform(
        cust_grp[['Recency', 'Frequency', 'Monetary']]
    )
else:
    cust_grp[['Recency_s', 'Frequency_s', 'Monetary_s']] = pd.DataFrame(columns=['Recency_s', 'Frequency_s', 'Monetary_s'])

N_CLUSTERS = 4
if not cust_grp.empty:
    kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=42, n_init='auto')
    cust_grp['cluster'] = kmeans.fit_predict(cust_grp[['Recency_s', 'Frequency_s', 'Monetary_s']])
else:
    cust_grp['cluster'] = []

# Map cluster label back to retail_df
if not retail_df.empty and not cust_grp.empty:
    retail_df = retail_df.merge(cust_grp[['CustomerID', 'cluster']], on='CustomerID', how='left')
    retail_df['cluster'] = retail_df['cluster'].fillna(-1).astype(int)
else:
    retail_df['cluster'] = -1

if product_col and product_col in retail_df.columns:
    list_price = retail_df.groupby(product_col)['Price'].median().reset_index().rename(columns={'Price': 'list_price'})
    retail_df = retail_df.merge(list_price, on=product_col, how='left')
    multipliers = np.array([0.8, 0.9, 1.0, 1.1, 1.2])
    candidate_prices = {
        row[product_col]: (multipliers * float(row['list_price'])).tolist()
        for _, row in list_price.iterrows()
        if pd.notnull(row['list_price'])
    }
else:
    candidate_prices = {}

demand_df.columns = [c.lower().replace(' ', '_') for c in demand_df.columns]
required = ['date', 'store_id', 'product_id', 'units_sold', 'price']
for c in required:
    if c not in demand_df.columns:
        raise ValueError(f"Required column '{c}' not found in demand dataset. Found: {demand_df.columns.tolist()}")

demand_df['units_sold'] = pd.to_numeric(demand_df['units_sold'], errors='coerce').fillna(0).astype(float)
demand_df['price'] = pd.to_numeric(demand_df['price'], errors='coerce').fillna(0.0).astype(float)
if 'inventory_level' in demand_df.columns:
    demand_df['inventory_level'] = pd.to_numeric(demand_df['inventory_level'], errors='coerce').fillna(0)

agg = demand_df.groupby(['date', 'store_id', 'product_id']).agg({
    'units_sold': 'sum',
    'price': 'median',
    'inventory_level': 'mean' if 'inventory_level' in demand_df.columns else 'sum'
}).reset_index()

agg.rename(columns={
    'units_sold': 'units_sold_daily',
    'price': 'price_median',
    'inventory_level': 'inventory_level_avg'
}, inplace=True)

if product_col and product_col in retail_df.columns:
    retail_df_tmp = retail_df.copy()
    retail_df_tmp['date'] = pd.to_datetime(retail_df_tmp['InvoiceDate']).dt.date
    retail_df_tmp['date'] = pd.to_datetime(retail_df_tmp['date'])
    retail_df_tmp = retail_df_tmp.rename(columns={product_col: 'product_id'})
    merged = retail_df_tmp.merge(agg, on=['date', 'product_id'], how='left')
else:
    merged = retail_df.copy()

agg['date'] = pd.to_datetime(agg['date'])
agg = agg.sort_values(['product_id', 'store_id', 'date'])
train_df, test_df = train_test_split(agg, test_size=0.2, shuffle=False)

os.makedirs('processed', exist_ok=True)
cust_grp.to_csv('processed/customer_rfm_clusters.csv', index=False)
if 'CustomerID' in merged.columns:
    merged['CustomerID'] = merged['CustomerID'].astype(str)
merged.to_parquet('processed/retail_merged.parquet', index=False)
agg.to_parquet('processed/demand_agg.parquet', index=False)
train_df.to_parquet('processed/demand_train.parquet', index=False)
test_df.to_parquet('processed/demand_test.parquet', index=False)

print("✅ Preprocessing complete. Artifacts saved in ./processed/")

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import OneHotEncoder
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')
train_df = pd.read_parquet('processed/demand_train.parquet')
test_df  = pd.read_parquet('processed/demand_test.parquet')

print(f"Train: {train_df.shape}, Test: {test_df.shape}")
def create_features(df):
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    df['day_of_week'] = df['date'].dt.dayofweek
    df['month'] = df['date'].dt.month
    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)
    df['price_log'] = np.log1p(df['price_median'])

    df = df.sort_values(['product_id', 'store_id', 'date'])
    df['units_sold_lag1'] = df.groupby(['product_id', 'store_id'])['units_sold_daily'].shift(1)
    df['units_sold_lag7'] = df.groupby(['product_id', 'store_id'])['units_sold_daily'].shift(7)
    df['price_lag1'] = df.groupby(['product_id', 'store_id'])['price_median'].shift(1)
    df['units_sold_roll7'] = df.groupby(['product_id', 'store_id'])['units_sold_daily']\
                               .transform(lambda x: x.rolling(7, min_periods=1).mean())

    df['units_sold_lag1'] = df['units_sold_lag1'].fillna(0)
    df['units_sold_lag7'] = df['units_sold_lag7'].fillna(0)
    df['price_lag1'] = df['price_lag1'].fillna(df['price_median'])
    return df

train_df = create_features(train_df)
test_df  = create_features(test_df)
num_cols = ['price_median', 'price_log', 'day_of_week', 'month', 'is_weekend',
            'inventory_level_avg', 'units_sold_lag1', 'units_sold_lag7',
            'units_sold_roll7', 'price_lag1']

cat_cols = ['store_id', 'product_id']

encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore', drop='first')
train_cat = encoder.fit_transform(train_df[cat_cols])
test_cat  = encoder.transform(test_df[cat_cols])

X_train = np.hstack([train_df[num_cols].values, train_cat])
X_test  = np.hstack([test_df[num_cols].values, test_cat])

y_train = train_df['units_sold_daily'].values
y_test  = test_df['units_sold_daily'].values

print(f"X_train shape: {X_train.shape}")
model = xgb.XGBRegressor(
    n_estimators=300,
    learning_rate=0.05,
    max_depth=7,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    tree_method='hist',
    objective='reg:squarederror'
)

model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=100)

y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f"\nDemand Model → MAE: {mae:.2f} | RMSE: {rmse:.2f} | R²: {r2:.4f}")
base_prices = test_df.groupby('product_id')['price_median'].median()
candidate_prices = {}

for pid, base in base_prices.items():
    if pd.notna(base) and base > 0:
        candidate_prices[pid] = np.round(np.array([0.8, 0.9, 1.0, 1.1, 1.2]) * base, 2)

print(f"Created candidate prices for {len(candidate_prices)} products → SUCCESS!")
latest_df = test_df.sort_values('date').groupby(['product_id', 'store_id']).tail(1).reset_index(drop=True)
print(f"Latest sales contexts: {len(latest_df)}")
results = []

for idx, row in latest_df.iterrows():
    pid = row['product_id']
    if pid not in candidate_prices:
        continue

    prices = candidate_prices[pid]
    best_revenue = -1
    best_price = None
    best_sales = None
    cat_vector = test_cat[idx]

    for p in prices:
        num_vector = np.array([
            p, np.log1p(p),
            row['day_of_week'], row['month'], row['is_weekend'],
            row['inventory_level_avg'],
            row['units_sold_lag1'], row['units_sold_lag7'], row['units_sold_roll7'],
            p
        ])
        X_temp = np.hstack([num_vector, cat_vector]).reshape(1, -1)
        pred_sales = max(0, model.predict(X_temp)[0])
        revenue = pred_sales * p

        if revenue > best_revenue:
            best_revenue = revenue
            best_price = p
            best_sales = pred_sales

    current_rev = row['units_sold_daily'] * row['price_median']
    uplift = (best_revenue / current_rev - 1) * 100 if current_rev > 0 else 0

    results.append({
        'product_id': pid,
        'store_id': row['store_id'],
        'current_price': round(row['price_median'], 2),
        'optimal_price': best_price,
        'price_change_%': round((best_price / row['price_median'] - 1) * 100, 1),
        'current_revenue': round(current_rev, 2),
        'predicted_revenue_optimal': round(best_revenue, 2),
        'revenue_uplift_%': round(uplift, 1),
        'predicted_sales_at_optimal': round(best_sales, 1)
    })

results_df = pd.DataFrame(results)

print(f"\nOPTIMAL PRICING RECOMMENDATIONS: {len(results_df)} products")
print(results_df.head(10))

print(f"\nAverage revenue uplift: {results_df['revenue_uplift_%'].mean():.1f}%")
print(f"Price increase recommended: {len(results_df[results_df['price_change_%'] > 0])} products ({(results_df['price_change_%'] > 0).mean()*100:.0f}%)")
print(f"Price decrease recommended: {len(results_df[results_df['price_change_%'] < 0])} products ({(results_df['price_change_%'] < 0).mean()*100:.0f}%)")

# Save
results_df.to_csv('processed/optimal_pricing_recommendations.csv', index=False)
print("\nResults saved!")
if len(results_df) > 0:
    best_row = results_df.loc[results_df['revenue_uplift_%'].idxmax()]
    pid = best_row['product_id']
    row = latest_df[latest_df['product_id'] == pid].iloc[0]
    idx_plot = latest_df[latest_df['product_id'] == pid].index[0]
    prices = candidate_prices[pid]

    sales_curve = []
    revenue_curve = []
    cat_vec = test_cat[idx_plot]

    for p in prices:
        num = np.array([p, np.log1p(p), row['day_of_week'], row['month'], row['is_weekend'],
                        row['inventory_level_avg'], row['units_sold_lag1'],
                        row['units_sold_lag7'], row['units_sold_roll7'], p])
        X = np.hstack([num, cat_vec]).reshape(1, -1)
        s = max(0, model.predict(X)[0])
        sales_curve.append(s)
        revenue_curve.append(s * p)

    plt.figure(figsize=(13, 5))
    plt.subplot(1, 2, 1)
    plt.plot(prices, sales_curve, 'o-', color='steelblue', linewidth=2, markersize=8)
    plt.title(f"Demand Curve – {pid}\n(Uplift: {best_row['revenue_uplift_%']:.1f}%)", fontsize=13)
    plt.xlabel("Price"); plt.ylabel("Units Sold"); plt.grid(alpha=0.3)

    plt.subplot(1, 2, 2)
    plt.plot(prices, revenue_curve, 'o-', color='green', linewidth=2, markersize=8)
    plt.axvline(best_row['optimal_price'], color='red', linestyle='--', linewidth=3,
                label=f"Optimal Price = {best_row['optimal_price']}")
    plt.title("Revenue Curve", fontsize=13)
    plt.xlabel("Price"); plt.ylabel("Revenue"); plt.legend(); plt.grid(alpha=0.3)

    plt.suptitle("Dynamic Pricing Engine – Final Result", fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.show()

print("\n" + "="*85)
print("        DYNAMIC PRICING PROJECT 100% COMPLETE & SUCCESSFUL!")
print(f"        Model R² = {r2:.3f} | Recommendations = {len(results_df)} | Avg Uplift = {results_df['revenue_uplift_%'].mean():.1f}%")
print("="*85)